#version 450
#extension GL_EXT_mesh_shader : require
#extension GL_EXT_shader_explicit_arithmetic_types_int8 : require
#extension GL_EXT_samplerless_texture_functions : require

#if defined(VARIANT_BIT_2) && VARIANT_BIT_2
#define MESHLET_PRIMITIVE_CULL_WAVE32 1
#else
#define MESHLET_PRIMITIVE_CULL_WAVE32 0
#endif

#if defined(VARIANT_BIT_0) && VARIANT_BIT_0
#define MESHLET_RENDER_TASK_HIERARCHICAL 1
#else
#define MESHLET_RENDER_TASK_HIERARCHICAL 0
#endif

#if defined(VARIANT_BIT_3) && VARIANT_BIT_3
#define MESHLET_RENDER_PHASE 1
#elif defined(VARIANT_BIT_4) && VARIANT_BIT_4
#define MESHLET_RENDER_PHASE 2
#else
#define MESHLET_RENDER_PHASE 0
#endif

layout(local_size_x = 32) in;

#if defined(VARIANT_BIT_5) && VARIANT_BIT_5
#define MESHLET_RENDER_FORCE_VISIBLE
#endif

#if MESHLET_PRIMITIVE_CULL_WAVE32
#extension GL_KHR_shader_subgroup_basic : require
#extension GL_KHR_shader_subgroup_shuffle : require
#extension GL_KHR_shader_subgroup_ballot : require
#extension GL_KHR_shader_subgroup_arithmetic : require
#endif


#include "inc/meshlet_render.h"
#include "inc/render_parameters.h"

layout(push_constant, std430) uniform Registers
{
    uint offset;
    uint count;
} registers;

taskPayloadSharedEXT CompactedDrawInfoPayload mesh_payload;

shared uint ballot_value;
uvec4 ballot(bool v)
{
#if MESHLET_PRIMITIVE_CULL_WAVE32
    if (gl_SubgroupSize == 32)
        return subgroupBallot(v);
#endif

    barrier();
    if (gl_LocalInvocationIndex == 0)
        ballot_value = 0;
    barrier();
    if (v)
        atomicOr(ballot_value, 1u << gl_LocalInvocationIndex);
    barrier();
    return uvec4(ballot_value, 0, 0, 0);
}

uint ballotBitCount(uvec4 v)
{
#if MESHLET_PRIMITIVE_CULL_WAVE32
    if (gl_SubgroupSize == 32)
        return subgroupBallotBitCount(v);
#endif

    return bitCount(v.x);
}

uint ballotExclusiveBitCount(uvec4 v)
{
#if MESHLET_PRIMITIVE_CULL_WAVE32
    if (gl_SubgroupSize == 32)
        return subgroupBallotExclusiveBitCount(v);
#endif

    return bitCount(bitfieldExtract(v.x, 0, int(gl_LocalInvocationIndex)));
}

uint payload_offset = 0;

void process_task(MeshAssetDrawTaskInfo task)
{
    uint node_instance = task.node_instance;
    uint material_flags = task.material_flags;
    uint mesh_index_count = task.mesh_index_count;

    uint offset = mesh_index_count & ~31u;
    uint count = bitfieldExtract(mesh_index_count, 0, 5) + 1;
    uint meshlet_index = offset + gl_LocalInvocationIndex;

#if MESHLET_RENDER_PHASE >= 1
    uint visibility_state = occluders.data[task.occluder_state_offset];
#endif

    bool alloc_draw = false;
    if (gl_LocalInvocationIndex < count)
    {
        mat_affine M = transforms.data[node_instance];
        Bound b = bounds.data[meshlet_index];

#if MESHLET_RENDER_PHASE == 1
        if (bitfieldExtract(visibility_state, int(gl_LocalInvocationIndex), 1) != 0)
            alloc_draw = cluster_cull(M, b, global.camera_position);
#else
        alloc_draw = cluster_cull(M, b, global.camera_position);
#endif
    }

    uvec4 draw_ballot = ballot(alloc_draw);

#if MESHLET_RENDER_PHASE == 2
    // Record all clusters that are considered visible in this frame.
    if (gl_LocalInvocationIndex == 0)
        occluders.data[task.occluder_state_offset] = draw_ballot.x;

#ifndef MESHLET_RENDER_FORCE_VISIBLE
    // If we already rendered in phase 1, skip the draw here.
    // If we only did a Z-prepass, we may still need to render to fill in the attachments properly.
    // Doing Z-prepass helps mask bad task shader behavior on at least AMD.
    if (bitfieldExtract(visibility_state, int(gl_LocalInvocationIndex), 1) != 0)
        alloc_draw = false;

    draw_ballot = ballot(alloc_draw);
#endif
#endif

    uint draw_count = ballotBitCount(draw_ballot);
    uint local_offset = ballotExclusiveBitCount(draw_ballot);

#if MESHLET_RENDER_TASK_HIERARCHICAL
    if (alloc_draw)
    {
        mesh_payload.infos[payload_offset + local_offset] =
            CompactedDrawInfo(meshlet_index, node_instance, material_flags);
    }
#else
    if (gl_LocalInvocationIndex == 0)
        mesh_payload.info = CompactedDrawInfo(offset, node_instance, material_flags);
    if (alloc_draw)
        mesh_payload.offsets[local_offset] = uint8_t(gl_LocalInvocationIndex);
#endif

    payload_offset += draw_count;
}

void main()
{
#if MESHLET_RENDER_TASK_HIERARCHICAL
    uint task_index = registers.offset + gl_GlobalInvocationID.x;
    bool task_needs_work = false;

    if (gl_GlobalInvocationID.x < registers.count)
    {
        MeshAssetDrawTaskInfo task = task_info.data[task_index];

        // Cull the group.
        AABB aabb = aabb.data[task.aabb_instance];
        bool visible = frustum_cull(aabb.lo, aabb.hi);

#if MESHLET_RENDER_PHASE == 1
        task_needs_work = visible && occluders.data[task.occluder_state_offset] != 0;
#else
        task_needs_work = visible;
#if MESHLET_RENDER_PHASE == 2
        // Nothing is visible, clear out occluder state.
        if (!task_needs_work)
            occluders.data[task.occluder_state_offset] = 0;
#endif
#endif
    }

    // If we're not doing hierarchical culling, go straight to cluster culling.

    uint b = ballot(task_needs_work).x;

    while (b != 0)
    {
        int lane = findLSB(b);
        b &= b - 1;
        MeshAssetDrawTaskInfo tmp_task = task_info.data[gl_WorkGroupID.x * gl_WorkGroupSize.x + registers.offset + lane];
        process_task(tmp_task);
    }
#else
    uint task_index = gl_WorkGroupID.x + registers.offset;
    MeshAssetDrawTaskInfo task = task_info.data[task_index];
    process_task(task);
#endif

    EmitMeshTasksEXT(8, payload_offset, 1);
}
